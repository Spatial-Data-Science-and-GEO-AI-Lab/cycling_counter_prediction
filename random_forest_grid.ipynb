{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from math import sqrt\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Best score:  -0.6777389949241421\n"
     ]
    }
   ],
   "source": [
    "#Load in data\n",
    "#Import csv and remove non-numerical variables\n",
    "df = pd.read_csv('weekly_new.csv')\n",
    "df = df.drop(['city', 'name', 'year', 'week', 'latitude', 'longitude', 'espg'] , axis=1)\n",
    "df = df[['counts_week', 'country', '3_way_int_count', '4_way_int_count', 'dist_to_greenspace', 'bike_points',\n",
    "            'bus_stops', 'restaurants', 'cycle_length', 'dem_std', 'lst_std', 'pop_sum', 'dem_mean', 'shop_list']]\n",
    "\n",
    "#Select country and drop column\n",
    "country = df[df['country'] == 'Netherlands']\n",
    "country = country.drop('country', axis=1)\n",
    "\n",
    "#Count variable as stratify\n",
    "y = country.loc[:,'counts_week']\n",
    "X = country.drop('counts_week', axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Standardize y variable\n",
    "scaler = StandardScaler()\n",
    "y_train = scaler.fit_transform(y_train.values.reshape(-1, 1))\n",
    "y_train = y_train.ravel()\n",
    "y_test = scaler.transform(y_test.values.reshape(-1, 1))\n",
    "\n",
    "# Define the parameter grid to search\n",
    "param_grid = {'n_estimators': [50, 100, 200],\n",
    "              'max_depth': [None, 5, 10, 20],\n",
    "              'min_samples_split': [2, 5, 10]}\n",
    "\n",
    "# Create the random forest model\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "# Create the K-fold cross-validation object\n",
    "kf = KFold(n_splits=10)\n",
    "\n",
    "# Create the grid search object\n",
    "grid_search = GridSearchCV(rf, param_grid, cv=kf, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and score\n",
    "print(\"Best parameters: \", grid_search.best_params_)\n",
    "print(\"Best score: \", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared:  0.27445806494342984\n",
      "MSE:  1.6182007721428437\n",
      "RMSE:  1.2720852063218264\n",
      "MAE:  0.6021136942769878\n"
     ]
    }
   ],
   "source": [
    "# Get the best model from the grid search\n",
    "model_forest = grid_search.best_estimator_\n",
    "\n",
    "# Use the best model to make predictions on the test set\n",
    "y_pred = model_forest.predict(X_test)\n",
    "\n",
    "# Calculate the R-squared, RMSE, MSE and F1-score\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = sqrt(mse)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(\"R-squared: \", r2)\n",
    "print(\"MSE: \", mse)\n",
    "print(\"RMSE: \", rmse)\n",
    "print(\"MAE: \", mae)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Best parameters:  {'colsample_bytree': 1, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 50, 'subsample': 1}\n",
      "Best score:  -0.6041355675372122\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "\n",
    "# Define the parameter grid to search\n",
    "param_grid = {'n_estimators': [50, 100, 200],\n",
    "              'max_depth': [3, 5, 10],\n",
    "              'learning_rate': [0.1, 0.5, 1],\n",
    "              'subsample': [0.8, 1],\n",
    "              'colsample_bytree': [0.8, 1]\n",
    "              }\n",
    "\n",
    "# Create the XGBoost model\n",
    "xgb_reg = xgb.XGBRegressor(objective ='reg:squarederror')\n",
    "\n",
    "# Create the K-fold cross-validation object\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "# Create the grid search object\n",
    "grid_search = GridSearchCV(xgb_reg,\n",
    "                   param_grid=param_grid,\n",
    "                   scoring='neg_mean_squared_error',\n",
    "                   cv=5,\n",
    "                   verbose=True)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and score\n",
    "print(\"Best parameters: \", grid_search.best_params_)\n",
    "print(\"Best score: \", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared:  0.23169240995894902\n",
      "MSE:  1.71358246212288\n",
      "RMSE:  1.3090387550118139\n",
      "MAE:  0.5947602570184656\n"
     ]
    }
   ],
   "source": [
    "best_params = grid_search.best_params_\n",
    "\n",
    "model_xgb = xgb.XGBRegressor(**best_params)\n",
    "\n",
    "# Get the predictions of the model on the test data\n",
    "model_xgb.fit(X_train, y_train)\n",
    "y_pred = model_xgb.predict(X_test)\n",
    "\n",
    "# Calculate the R-squared, RMSE, MSE and F1-score\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = sqrt(mse)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(\"R-squared: \", r2)\n",
    "print(\"MSE: \", mse)\n",
    "print(\"RMSE: \", rmse)\n",
    "print(\"MAE: \", mae)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "Best parameters:  {'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "Best score:  -1.0078467678287928\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "# Define the parameter grid to search\n",
    "param_grid = {'C': [0.1, 1, 10],\n",
    "              'gamma': [0.1, 1, 10],\n",
    "              'kernel': ['linear', 'rbf']\n",
    "              }\n",
    "\n",
    "# Create the SVM model\n",
    "svm = SVR()\n",
    "\n",
    "# Create the K-fold cross-validation object\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "# Create the grid search object\n",
    "grid_search = GridSearchCV(svm,\n",
    "                   param_grid=param_grid,\n",
    "                   scoring='neg_mean_squared_error',\n",
    "                   cv=kf,\n",
    "                   verbose=True)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and score\n",
    "print(\"Best parameters: \", grid_search.best_params_)\n",
    "print(\"Best score: \", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = grid_search.best_params_\n",
    "\n",
    "model_xgb = xgb.XGBRegressor(**best_params)\n",
    "\n",
    "# Get the predictions of the model on the test data\n",
    "model_xgb.fit(X_train, y_train)\n",
    "y_pred = model_xgb.predict(X_test)\n",
    "\n",
    "# Calculate the R-squared, RMSE, MSE and F1-score\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = sqrt(mse)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(\"R-squared: \", r2)\n",
    "print(\"MSE: \", mse)\n",
    "print(\"RMSE: \", rmse)\n",
    "print(\"MAE: \", mae)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Block variable for spatial autocorrelation\n",
    "\n",
    "List of variables:\n",
    "- counts week\n",
    "- street per node\n",
    "- streeth length total\n",
    "- circuity\n",
    "- 3 way int\n",
    "- all distance\n",
    "- all points\n",
    "- cycle length\n",
    "- ndvi mean\n",
    "- dem std\n",
    "- pop sum\n",
    "- lst mean\n",
    "- built env\n",
    "- entropy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0 | packaged by conda-forge | (main, Jan 14 2023, 12:26:40) [Clang 14.0.6 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e04e9d70aa0476d320a89e4247bc687a844ab51af6dd849df37511de572e0dcf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
