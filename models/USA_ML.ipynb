{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import statsmodels.api as sm\n",
    "from math import sqrt\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# United States of America"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load in data\n",
    "#Import csv and remove non-numerical variables\n",
    "df = pd.read_csv('weekly_new.csv')\n",
    "df = df.drop(['name', 'year', 'week', 'latitude', 'longitude', 'espg'] , axis=1)\n",
    "\n",
    "df = df[['counts_week' ,'country', 'dist_to_greenspace', 'dist_to_edu', 'bike_points', 'bus_stops', 'business_shops', 'traffic_signals', 'cycle_length',\n",
    "         'lst_mean', 'pop_sum', 'build_area', 'ndvi_mean', 'dist_to_bikePOI', 'dist_to_train', '3_way_int_count', 'median_speed', 'orientation_entropy', 'lc_entropy',\n",
    "         'restaurants', 'dem_mean', 'dem_std']]\n",
    "\n",
    "country = df[df['country'] == 'USA']\n",
    "\n",
    "#Create dependent and independent variable\n",
    "y = country.loc[:,'counts_week']\n",
    "X = country.drop(['counts_week', 'country'], axis=1)\n",
    "\n",
    "# # Normalize dependent variable\n",
    "# scaler = StandardScaler()\n",
    "# data_scaled = scaler.fit_transform(y.values.reshape(-1, 1))\n",
    "# y = pd.Series(data_scaled.ravel())\n",
    "\n",
    "#Use natural log as normalization\n",
    "y = np.log(y + 1e-8).round(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create traintestsplit for machine learning models\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression (OLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add a constant to the data and run OLS regression\n",
    "Xc = sm.add_constant(X)\n",
    "Xc.reset_index(drop=True, inplace=True)\n",
    "y.reset_index(drop=True, inplace=True)\n",
    "model = sm.OLS(y, Xc).fit()\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract coefficients and p-values\n",
    "params = model.params\n",
    "pvalues = model.pvalues\n",
    "\n",
    "# Create DataFrame\n",
    "df_coef = pd.DataFrame({'coef': params, 'pvalue': pvalues}).round(3)\n",
    "df_coef.to_csv('coef.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict target variable using the OLS model\n",
    "y_pred = model.predict(Xc)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "mse = mean_squared_error(y, y_pred)\n",
    "rmse = mean_squared_error(y, y_pred, squared=False)\n",
    "mae = mean_absolute_error(y, y_pred)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"MSE: \", mse)\n",
    "print(\"RMSE: \", rmse)\n",
    "print(\"MAE: \", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check multicolinearity with VIF\n",
    "vif = pd.DataFrame()\n",
    "vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "vif[\"features\"] = X.columns\n",
    "\n",
    "print(vif)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid to search\n",
    "param_grid = {'n_estimators': [50, 100, 200, 300, 400, 500],\n",
    "            'max_depth': [5, 10, 15, 20, 25],\n",
    "            'min_samples_split': [2, 5, 10]}\n",
    "\n",
    "# Create the random forest model\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "# Create the K-fold cross-validation object\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "# Create the grid search object\n",
    "grid_search = GridSearchCV(rf, param_grid, cv=kf, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and score\n",
    "print(\"Best parameters: \", grid_search.best_params_)\n",
    "print(\"Best score: \", grid_search.best_score_)\n",
    "\n",
    "#Create model from best parameters\n",
    "best_params = grid_search.best_params_\n",
    "model_rf = RandomForestRegressor(**best_params)\n",
    "\n",
    "#Run the model on the test split of the data\n",
    "model_rf.fit(X_train, y_train)\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "#Calculate model statistics and print them\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = sqrt(mse)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(\"R-squared: \", r2)\n",
    "print(\"MSE: \", mse)\n",
    "print(\"RMSE: \", rmse)\n",
    "print(\"MAE: \", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "with open('/Users/winke/Documents/University/Thesis/Predicting_cycling/models/standardized/us_rf_3.pkl', 'wb') as f:\n",
    "    pickle.dump(model_rf, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "\n",
    "# Define the parameter grid to search\n",
    "param_grid = {'n_estimators': [50, 100, 200, 250, 300, 400],\n",
    "              'max_depth': [3, 5, 10, 15],\n",
    "              'learning_rate': [0.1, 0.3, 0.5, 1],\n",
    "              'subsample': [0.8, 1],\n",
    "              'colsample_bytree': [0.8, 1]\n",
    "              }\n",
    "\n",
    "# Create the XGBoost model\n",
    "xgb_reg = xgb.XGBRegressor(objective ='reg:squarederror')\n",
    "\n",
    "# Create the K-fold cross-validation object\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "# Create the grid search object\n",
    "grid_search = GridSearchCV(xgb_reg,\n",
    "                param_grid=param_grid,\n",
    "                cv=kf,\n",
    "                scoring='neg_mean_squared_error',\n",
    "                verbose=True)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and score\n",
    "print(\"Best parameters: \", grid_search.best_params_)\n",
    "print(\"Best score: \", grid_search.best_score_)\n",
    "\n",
    "#Create model from best parameters\n",
    "best_params = grid_search.best_params_\n",
    "model_xgb = xgb.XGBRegressor(**best_params)\n",
    "\n",
    "# Get the predictions of the model on the test data\n",
    "model_xgb.fit(X_train, y_train)\n",
    "y_pred = model_xgb.predict(X_test)\n",
    "\n",
    "# Calculate the R-squared, RMSE, MSE and F1-score\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = sqrt(mse)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(\"R-squared: \", r2)\n",
    "print(\"MSE: \", mse)\n",
    "print(\"RMSE: \", rmse)\n",
    "print(\"MAE: \", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "with open('/Users/winke/Documents/University/Thesis/Predicting_cycling/models/standardized/us_xgb_2.pkl', 'wb') as f:\n",
    "    pickle.dump(model_xgb, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid to search\n",
    "param_grid = {'C': [0.1, 1, 10, 100, 1000],\n",
    "              'gamma': [0.001, 0.01, 0.1, 1],\n",
    "              'kernel': ['rbf']\n",
    "              }\n",
    "\n",
    "# Create the SVM model\n",
    "svm_reg = SVR()\n",
    "\n",
    "# Create the K-fold cross-validation object\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "# Create the grid search object\n",
    "grid_search = GridSearchCV(svm_reg,\n",
    "                param_grid=param_grid,\n",
    "                cv=kf,\n",
    "                scoring='neg_mean_squared_error',\n",
    "                verbose=True)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and score\n",
    "print(\"Best parameters: \", grid_search.best_params_)\n",
    "print(\"Best score: \", grid_search.best_score_)\n",
    "\n",
    "#Create model from best parameters\n",
    "best_params = grid_search.best_params_\n",
    "model_svm = SVR(**best_params)\n",
    "\n",
    "# Get the predictions of the model on the test data\n",
    "model_svm.fit(X_train, y_train)\n",
    "y_pred = model_svm.predict(X_test)\n",
    "\n",
    "# Calculate the R-squared, RMSE, MSE and F1-score\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = sqrt(mse)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(\"R-squared: \", r2)\n",
    "print(\"MSE: \", mse)\n",
    "print(\"RMSE: \", rmse)\n",
    "print(\"MAE: \", mae)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8794ba5723f3a63e895a9300187a0c279dca75a37113b6a48c61e29ffb05a139"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
